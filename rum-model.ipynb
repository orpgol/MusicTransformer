{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf51b06-946b-4a92-8d9d-29aa650d8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,argparse\n",
    "import csv\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from dataset.e_piano import create_epiano_datasets, compute_epiano_accuracy\n",
    "\n",
    "from model.music_transformer import MusicTransformer\n",
    "from model.loss import SmoothCrossEntropyLoss\n",
    "\n",
    "from utilities.constants import *\n",
    "from utilities.device import get_device, use_cuda\n",
    "from utilities.lr_scheduling import LrStepTracker, get_lr\n",
    "from utilities.argument_funcs import parse_train_args, print_train_args, write_model_params\n",
    "from utilities.run_model import train_epoch, eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ab3f10-8310-4da0-9bbc-5681262087af",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = [\"Epoch\", \"Learn rate\", \"Avg Train loss\", \"Train Accuracy\", \"Avg Eval loss\", \"Eval accuracy\"]\n",
    "\n",
    "# Baseline is an untrained epoch that we evaluate as a baseline loss and accuracy\n",
    "BASELINE_EPOCH = -1\n",
    "\n",
    "# main\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ----------\n",
    "    Author: Damon Gwinn\n",
    "    ----------\n",
    "    Entry point. Trains a model specified by command line arguments\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    args = parse_train_args()\n",
    "    print_train_args(args)\n",
    "\n",
    "    if(args.force_cpu):\n",
    "        use_cuda(False)\n",
    "        print(\"WARNING: Forced CPU usage, expect model to perform slower\")\n",
    "        print(\"\")\n",
    "\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    ##### Output prep #####\n",
    "    params_file = os.path.join(args.output_dir, \"model_params.txt\")\n",
    "    write_model_params(args, params_file)\n",
    "\n",
    "    weights_folder = os.path.join(args.output_dir, \"weights\")\n",
    "    os.makedirs(weights_folder, exist_ok=True)\n",
    "\n",
    "    results_folder = os.path.join(args.output_dir, \"results\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    results_file = os.path.join(results_folder, \"results.csv\")\n",
    "    best_loss_file = os.path.join(results_folder, \"best_loss_weights.pickle\")\n",
    "    best_acc_file = os.path.join(results_folder, \"best_acc_weights.pickle\")\n",
    "    best_text = os.path.join(results_folder, \"best_epochs.txt\")\n",
    "\n",
    "    ##### Tensorboard #####\n",
    "    if(args.no_tensorboard):\n",
    "        tensorboard_summary = None\n",
    "    else:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "        tensorboad_dir = os.path.join(args.output_dir, \"tensorboard\")\n",
    "        tensorboard_summary = SummaryWriter(log_dir=tensorboad_dir)\n",
    "\n",
    "    ##### Datasets #####\n",
    "    # train_dataset, val_dataset, test_dataset = create_epiano_datasets(args.input_dir, args.max_sequence)\n",
    "    \n",
    "    train_dataset = torchaudio.datasets.MUSDB_HQ('dataset/', \"train\", \n",
    "                                     download=False, \n",
    "                                     sources=[\"mixture\"], #[\"bass\", \"drums\", \"other\", \"mixture\", \"vocals\"]\n",
    "                                     split=\"train\") \n",
    "    val_dataset = torchaudio.datasets.MUSDB_HQ('dataset/', \"train\", \n",
    "                                     download=False, \n",
    "                                     sources=[\"mixture\"], #[\"bass\", \"drums\", \"other\", \"mixture\", \"vocals\"]\n",
    "                                     split=\"validation\") \n",
    "    test_dataset = torchaudio.datasets.MUSDB_HQ('dataset/', \"test\", \n",
    "                                     download=False, \n",
    "                                     sources=[\"mixture\"], #[\"bass\", \"drums\", \"other\", \"mixture\", \"vocals\"]\n",
    "                                     ) \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.n_workers, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=args.n_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=args.n_workers)\n",
    "\n",
    "    model = MusicTransformer(n_layers=args.n_layers, num_heads=args.num_heads,\n",
    "                d_model=args.d_model, dim_feedforward=args.dim_feedforward, dropout=args.dropout,\n",
    "                max_sequence=args.max_sequence, rpr=args.rpr).to(get_device())\n",
    "\n",
    "    ##### Continuing from previous training session #####\n",
    "    # start_epoch = BASELINE_EPOCH\n",
    "    start_epoch = 0\n",
    "    if(args.continue_weights is not None):\n",
    "        if(args.continue_epoch is None):\n",
    "            print(\"ERROR: Need epoch number to continue from (-continue_epoch) when using continue_weights\")\n",
    "            return\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(args.continue_weights))\n",
    "            start_epoch = args.continue_epoch\n",
    "    elif(args.continue_epoch is not None):\n",
    "        print(\"ERROR: Need continue weights (-continue_weights) when using continue_epoch\")\n",
    "        return\n",
    "\n",
    "    ##### Lr Scheduler vs static lr #####\n",
    "    if(args.lr is None):\n",
    "        if(args.continue_epoch is None):\n",
    "            init_step = 0\n",
    "        else:\n",
    "            init_step = args.continue_epoch * len(train_loader)\n",
    "\n",
    "        lr = LR_DEFAULT_START\n",
    "        lr_stepper = LrStepTracker(args.d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
    "    else:\n",
    "        lr = args.lr\n",
    "\n",
    "    ##### Not smoothing evaluation loss #####\n",
    "    eval_loss_func = nn.CrossEntropyLoss(ignore_index=TOKEN_PAD)\n",
    "\n",
    "    ##### SmoothCrossEntropyLoss or CrossEntropyLoss for training #####\n",
    "    if(args.ce_smoothing is None):\n",
    "        train_loss_func = eval_loss_func\n",
    "    else:\n",
    "        train_loss_func = SmoothCrossEntropyLoss(args.ce_smoothing, VOCAB_SIZE, ignore_index=TOKEN_PAD)\n",
    "\n",
    "    ##### Optimizer #####\n",
    "    opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
    "\n",
    "    if(args.lr is None):\n",
    "        lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    ##### Tracking best evaluation accuracy #####\n",
    "    best_eval_acc        = 0.0\n",
    "    best_eval_acc_epoch  = -1\n",
    "    best_eval_loss       = float(\"inf\")\n",
    "    best_eval_loss_epoch = -1\n",
    "\n",
    "    ##### Results reporting #####\n",
    "    if(not os.path.isfile(results_file)):\n",
    "        with open(results_file, \"w\", newline=\"\") as o_stream:\n",
    "            writer = csv.writer(o_stream)\n",
    "            writer.writerow(CSV_HEADER)\n",
    "\n",
    "\n",
    "    ##### TRAIN LOOP #####\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        # Baseline has no training and acts as a base loss and accuracy (epoch 0 in a sense)\n",
    "        if(epoch > BASELINE_EPOCH):\n",
    "            print(SEPERATOR)\n",
    "            print(\"NEW EPOCH:\", epoch+1)\n",
    "            print(SEPERATOR)\n",
    "            print(\"\")\n",
    "\n",
    "            # Train\n",
    "            train_epoch(epoch+1, model, train_loader, train_loss_func, opt, lr_scheduler, args.print_modulus)\n",
    "\n",
    "            print(SEPERATOR)\n",
    "            print(\"Evaluating:\")\n",
    "        else:\n",
    "            print(SEPERATOR)\n",
    "            print(\"Baseline model evaluation (Epoch 0):\")\n",
    "\n",
    "        # Eval\n",
    "        train_loss, train_acc = eval_model(model, train_loader, train_loss_func)\n",
    "        eval_loss, eval_acc = eval_model(model, test_loader, eval_loss_func)\n",
    "\n",
    "        # Learn rate\n",
    "        lr = get_lr(opt)\n",
    "\n",
    "        print(\"Epoch:\", epoch+1)\n",
    "        print(\"Avg train loss:\", train_loss)\n",
    "        print(\"Avg train acc:\", train_acc)\n",
    "        print(\"Avg eval loss:\", eval_loss)\n",
    "        print(\"Avg eval acc:\", eval_acc)\n",
    "        print(SEPERATOR)\n",
    "        print(\"\")\n",
    "\n",
    "        new_best = False\n",
    "\n",
    "        if(eval_acc > best_eval_acc):\n",
    "            best_eval_acc = eval_acc\n",
    "            best_eval_acc_epoch  = epoch+1\n",
    "            torch.save(model.state_dict(), best_acc_file)\n",
    "            new_best = True\n",
    "\n",
    "        if(eval_loss < best_eval_loss):\n",
    "            best_eval_loss       = eval_loss\n",
    "            best_eval_loss_epoch = epoch+1\n",
    "            torch.save(model.state_dict(), best_loss_file)\n",
    "            new_best = True\n",
    "\n",
    "        # Writing out new bests\n",
    "        if(new_best):\n",
    "            with open(best_text, \"w\") as o_stream:\n",
    "                print(\"Best eval acc epoch:\", best_eval_acc_epoch, file=o_stream)\n",
    "                print(\"Best eval acc:\", best_eval_acc, file=o_stream)\n",
    "                print(\"\")\n",
    "                print(\"Best eval loss epoch:\", best_eval_loss_epoch, file=o_stream)\n",
    "                print(\"Best eval loss:\", best_eval_loss, file=o_stream)\n",
    "\n",
    "\n",
    "        if(not args.no_tensorboard):\n",
    "            tensorboard_summary.add_scalar(\"Avg_CE_loss/train\", train_loss, global_step=epoch+1)\n",
    "            tensorboard_summary.add_scalar(\"Avg_CE_loss/eval\", eval_loss, global_step=epoch+1)\n",
    "            tensorboard_summary.add_scalar(\"Accuracy/train\", train_acc, global_step=epoch+1)\n",
    "            tensorboard_summary.add_scalar(\"Accuracy/eval\", eval_acc, global_step=epoch+1)\n",
    "            tensorboard_summary.add_scalar(\"Learn_rate/train\", lr, global_step=epoch+1)\n",
    "            tensorboard_summary.flush()\n",
    "\n",
    "        if((epoch+1) % args.weight_modulus == 0):\n",
    "            epoch_str = str(epoch+1).zfill(PREPEND_ZEROS_WIDTH)\n",
    "            path = os.path.join(weights_folder, \"epoch_\" + epoch_str + \".pickle\")\n",
    "            torch.save(model.state_dict(), path)\n",
    "\n",
    "        with open(results_file, \"a\", newline=\"\") as o_stream:\n",
    "            writer = csv.writer(o_stream)\n",
    "            writer.writerow([epoch+1, lr, train_loss, train_acc, eval_loss, eval_acc])\n",
    "\n",
    "    # Sanity check just to make sure everything is gone\n",
    "    if(not args.no_tensorboard):\n",
    "        tensorboard_summary.flush()\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a08b10a-ba42-40bf-a963-4b4fb1c153e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Start to Train the Model\n",
    "n_workers = 1\n",
    "batch_size = 1 #@param {type:\"slider\", min:0, max:8, step:1}\n",
    "number_of_training_epochs = 150 #@param {type:\"slider\", min:0, max:200, step:1}\n",
    "maximum_output_MIDI_sequence = 512 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
    "dim_feedforward = 256\n",
    "sys.argv = ['-output_dir=rpr', '--rpr', f'-batch_size={batch_size}', f'-epochs={number_of_training_epochs}', \n",
    "            f'-max_sequence={maximum_output_MIDI_sequence}', f'-n_workers={n_workers}', f'-dim_feedforward={dim_feedforward}'] #-n_layers -num_heads -d_model -dim_feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c900322-4283-41fd-9939-e6f6e7a09f54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "input_dir: ./dataset/e_piano\n",
      "output_dir: ./saved_models\n",
      "weight_modulus: 1\n",
      "print_modulus: 1\n",
      "\n",
      "n_workers: 1\n",
      "force_cpu: False\n",
      "tensorboard: True\n",
      "\n",
      "continue_weights: None\n",
      "continue_epoch: None\n",
      "\n",
      "lr: None\n",
      "ce_smoothing: None\n",
      "batch_size: 1\n",
      "epochs: 150\n",
      "\n",
      "rpr: True\n",
      "max_sequence: 512\n",
      "n_layers: 6\n",
      "num_heads: 8\n",
      "d_model: 512\n",
      "\n",
      "dim_feedforward: 256\n",
      "dropout: 0.1\n",
      "=========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orpgol/miniconda3/envs/mayk/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "NEW EPOCH: 1\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 1 / 86\n",
      "LR: 1.7469281074217108e-07\n",
      "Train loss: 5.779476165771484\n",
      "\n",
      "Time (s): 2.560912847518921\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 2 / 86\n",
      "LR: 3.4938562148434215e-07\n",
      "Train loss: 5.813246250152588\n",
      "\n",
      "Time (s): 0.037423133850097656\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 3 / 86\n",
      "LR: 5.240784322265132e-07\n",
      "Train loss: 5.797491073608398\n",
      "\n",
      "Time (s): 0.05300569534301758\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 4 / 86\n",
      "LR: 6.987712429686843e-07\n",
      "Train loss: 5.780543804168701\n",
      "\n",
      "Time (s): 0.018246173858642578\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 5 / 86\n",
      "LR: 8.734640537108554e-07\n",
      "Train loss: 5.787901878356934\n",
      "\n",
      "Time (s): 0.026134252548217773\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 6 / 86\n",
      "LR: 1.0481568644530265e-06\n",
      "Train loss: 5.730584144592285\n",
      "\n",
      "Time (s): 0.039263248443603516\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 7 / 86\n",
      "LR: 1.2228496751951975e-06\n",
      "Train loss: 5.715783596038818\n",
      "\n",
      "Time (s): 0.03907918930053711\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 8 / 86\n",
      "LR: 1.3975424859373686e-06\n",
      "Train loss: 5.594594955444336\n",
      "\n",
      "Time (s): 0.016358613967895508\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 9 / 86\n",
      "LR: 1.5722352966795397e-06\n",
      "Train loss: 5.60410737991333\n",
      "\n",
      "Time (s): 0.047020912170410156\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 10 / 86\n",
      "LR: 1.7469281074217108e-06\n",
      "Train loss: 5.563568115234375\n",
      "\n",
      "Time (s): 0.034668922424316406\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 11 / 86\n",
      "LR: 1.9216209181638816e-06\n",
      "Train loss: 5.509304523468018\n",
      "\n",
      "Time (s): 0.0332183837890625\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 12 / 86\n",
      "LR: 2.096313728906053e-06\n",
      "Train loss: 5.422591686248779\n",
      "\n",
      "Time (s): 0.03706836700439453\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 13 / 86\n",
      "LR: 2.271006539648224e-06\n",
      "Train loss: 5.431331634521484\n",
      "\n",
      "Time (s): 0.04331040382385254\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 14 / 86\n",
      "LR: 2.445699350390395e-06\n",
      "Train loss: 5.285758018493652\n",
      "\n",
      "Time (s): 0.04421067237854004\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 15 / 86\n",
      "LR: 2.620392161132566e-06\n",
      "Train loss: 5.25613260269165\n",
      "\n",
      "Time (s): 0.017235517501831055\n",
      "=========================\n",
      "\n",
      "=========================\n",
      "Epoch 1  Batch 16 / 86\n",
      "LR: 2.7950849718747372e-06\n",
      "Train loss: 5.099698066711426\n",
      "\n",
      "Time (s): 0.03597545623779297\n",
      "=========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 140\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_modulus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(SEPERATOR)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/mayk/MusicTransformer-Pytorch/utilities/run_model.py:43\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(cur_epoch, model, dataloader, loss, opt, lr_scheduler, print_modulus)\u001b[0m\n\u001b[1;32m     39\u001b[0m tgt \u001b[38;5;241m=\u001b[39m tgt\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     41\u001b[0m out \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mforward(y, tgt)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(lr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/mayk/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mayk/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0d86f-8ae8-4a47-9f5e-0dc03ace3f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad03ea6-6c8f-4ab3-9df8-99c3db22bec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bf4afe9-5da2-4249-ab7c-293b70bf8384",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e47100d-5f82-4908-bdb0-7a8593c78de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "musdb = torchaudio.datasets.MUSDB_HQ('dataset/', \"train\", \n",
    "                                     download=False, \n",
    "                                     sources=[\"mixture\"], #[\"bass\", \"drums\", \"other\", \"mixture\", \"vocals\"]\n",
    "                                     split=\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71307fec-3c26-4bd1-bc70-86331752438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    musdb,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10fb216-2001-415d-ac79-a4ccf10a74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(data_loader):\n",
    "    print(batch_num)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941875d9-da93-48b6-8f62-2c403116cf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 12136088])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae96dafd-67c0-46d5-94d2-2d731d15d998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 12136088])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "647e3f82-0da9-4457-a2f0-4869c3b0dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_train_args()\n",
    "train_dataset, val_dataset, test_dataset = create_epiano_datasets(args.input_dir, args.max_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c703bef-bfe7-41a9-9219-15f1deab96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b3f90fb-014e-483a-90eb-210d1e790881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(data_loader):\n",
    "    print(batch_num)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddeb244e-45d0-48e3-a78e-8a62db99bbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "468ea12e-9ff9-410f-85f9-27a315606a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_num, batch in enumerate(data_loader):\n",
    "\n",
    "\n",
    "        x   = batch[0].to(get_device())\n",
    "        tgt = batch[1].to(get_device())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac15c033-7eef-4cea-9730-60d553e04344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(torch.int64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f22e30c-ce8d-4c4a-8fe3-7d368af018f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00, -9.1553e-05, -9.1553e-05,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -6.1035e-05, -9.1553e-05,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a620604f-20ec-411c-81e7-6e11bcafafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b774dd-a4e9-44a5-ba69-b30835f705cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56a1ab6-e53a-4ee3-adf9-5d5d7997a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.functional import apply_codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfad1bf4-b2f0-4030-9248-4c05863705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = apply_codec(x.reshape([-1,x.shape[-1]]).cpu(), sample_rate=1024, format='mp3', channels_first=True, compression=None, \n",
    "            encoding=None, bits_per_sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c3c5965-538f-4cbc-a315-776c6362a923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1303659])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c246bba-8695-4a01-a3d3-601f404be84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 8903278])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "046022af-6fdf-4260-ab60-db595768e6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape([-1,x.shape[-1]])[:,:512].shape\n",
    "x.reshape([-1,x.shape[-1]])[:,512:1024].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58ea4d36-c421-43e9-84cc-9ab5d7a96a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed31f3-c48d-46e2-ab2f-7cf94464f775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maykEnv",
   "language": "python",
   "name": "maykenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
